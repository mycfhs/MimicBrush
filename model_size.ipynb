{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from safetensors.numpy import save_file, load_file\n",
    "from omegaconf import OmegaConf\n",
    "from transformers import AutoConfig\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "from diffusers import StableDiffusionPipeline, StableDiffusionImg2ImgPipeline, StableDiffusionInpaintPipelineLegacy, StableDiffusionInpaintPipeline, DDIMScheduler, AutoencoderKL\n",
    "from diffusers import AutoencoderKL, DDPMScheduler, UNet2DConditionModel, DDIMScheduler\n",
    "from diffusers import DDIMScheduler, DDPMScheduler, DPMSolverMultistepScheduler\n",
    "#\n",
    "from models.pipeline_mimicbrush import MimicBrushPipeline\n",
    "from models.ReferenceNet import ReferenceNet\n",
    "from models.depth_guider import DepthGuider\n",
    "from mimicbrush import MimicBrush_RefNet\n",
    "from dataset.data_utils import *\n",
    "noise_scheduler = DDIMScheduler(\n",
    "    num_train_timesteps=1000,\n",
    "    beta_start=0.00085,\n",
    "    beta_end=0.012,\n",
    "    beta_schedule=\"scaled_linear\",\n",
    "    clip_sample=False,\n",
    "    set_alpha_to_one=False,\n",
    "    steps_offset=1,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_configs = OmegaConf.load('./configs/inference.yaml')\n",
    "\n",
    "# === import Depth Anything ===\n",
    "import sys\n",
    "sys.path.append(\"./depthanything\")\n",
    "from torchvision.transforms import Compose\n",
    "from depthanything.fast_import import depth_anything_model \n",
    "from depthanything.depth_anything.util.transform import Resize, NormalizeImage, PrepareForNet\n",
    "transform = Compose([\n",
    "    Resize(\n",
    "        width=518,\n",
    "        height=518,\n",
    "        resize_target=False,\n",
    "        keep_aspect_ratio=True,\n",
    "        ensure_multiple_of=14,\n",
    "        resize_method='lower_bound',\n",
    "        image_interpolation_method=cv2.INTER_CUBIC,\n",
    "    ),\n",
    "    NormalizeImage(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    PrepareForNet(),\n",
    "])\n",
    "\n",
    "depth_anything_model.load_state_dict(torch.load(val_configs.model_path.depth_model))\n",
    "\n",
    "\n",
    "# === load the checkpoint ===\n",
    "base_model_path = val_configs.model_path.pretrained_imitativer_path\n",
    "vae_model_path = val_configs.model_path.pretrained_vae_name_or_path\n",
    "image_encoder_path = val_configs.model_path.image_encoder_path\n",
    "ref_model_path = val_configs.model_path.pretrained_reference_path\n",
    "mimicbrush_ckpt = val_configs.model_path.mimicbrush_ckpt_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vae = AutoencoderKL.from_pretrained(vae_model_path).to(dtype=torch.float16)\n",
    "unet = UNet2DConditionModel.from_pretrained(base_model_path, subfolder=\"unet\", in_channels=13, low_cpu_mem_usage=False, ignore_mismatched_sizes=True).to(dtype=torch.float16)\n",
    "\n",
    "pipe = MimicBrushPipeline.from_pretrained(\n",
    "    base_model_path,\n",
    "    torch_dtype=torch.float16,\n",
    "    scheduler=noise_scheduler,\n",
    "    vae=vae,\n",
    "    unet=unet,\n",
    "    feature_extractor=None,\n",
    "    safety_checker=None,\n",
    ")\n",
    "\n",
    "DEVICE = \"cuda:1\"\n",
    "torch.cuda.set_device(DEVICE)\n",
    "\n",
    "depth_guider = DepthGuider()\n",
    "referencenet = ReferenceNet.from_pretrained(ref_model_path, subfolder=\"unet\").to(dtype=torch.float16)\n",
    "mimicbrush_model = MimicBrush_RefNet(pipe, image_encoder_path, mimicbrush_ckpt,  depth_anything_model, depth_guider, referencenet, DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'clip_image_processor', 'depth_estimator', 'depth_guider', 'device', 'generate', 'get_image_embeds', 'image_encoder', 'image_encoder_path', 'image_processor', 'image_proj_model', 'init_proj', 'load_checkpoint', 'model_ckpt', 'pipe', 'referencenet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "['clip_image_processor', 'depth_estimator', 'depth_guider', 'device', 'generate', \n",
    " 'get_image_embeds', 'image_encoder', 'image_encoder_path', 'image_processor', \n",
    " 'image_proj_model', 'init_proj', 'load_checkpoint', 'model_ckpt', 'pipe', 'referencenet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mimicbrush_model.pipe.components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vae: 83,653,863 参数 (0.084B)\n",
      "text_encoder: 123,060,480 参数 (0.123B)\n",
      "unet: 859,546,884 参数 (0.860B)\n",
      "\n",
      "模型总参数量: 1,066,261,227\n",
      "以百万为单位: 1066.26M\n",
      "以十亿为单位: 1.07B\n",
      "image_encoder: 632,076,800 参数 (0.632B)\n",
      "depth_guider: 150,260 参数 (0.000B)\n",
      "referencenet: 857,066,560 参数 (0.857B)\n",
      "\n",
      "模型总参数量: 1,489,293,620\n",
      "以百万为单位: 1489.29M\n",
      "以十亿为单位: 1.49B\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# from transformers import AutoModel\n",
    "model = mimicbrush_model.pipe\n",
    "total_params = 0\n",
    "\n",
    "# 遍历模型的所有组件\n",
    "for component_name in model.components:\n",
    "    component = getattr(model, component_name)\n",
    "    if hasattr(component, \"parameters\"):\n",
    "        component_params = sum(p.numel() for p in component.parameters())\n",
    "        print(f\"{component_name}: {component_params:,} 参数 ({component_params/1e9:.3f}B)\")\n",
    "        total_params += component_params\n",
    "\n",
    "# 打印总参数量\n",
    "print(f\"\\n模型总参数量: {total_params:,}\")\n",
    "print(f\"以百万为单位: {total_params/1e6:.2f}M\")\n",
    "print(f\"以十亿为单位: {total_params/1e9:.2f}B\")\n",
    "\n",
    "\n",
    "model = mimicbrush_model\n",
    "total_params = 0\n",
    "\n",
    "# 遍历模型的所有组件\n",
    "\n",
    "_components = ['image_encoder', 'depth_guider', 'referencenet']\n",
    "for component_name in _components:\n",
    "    component = getattr(model, component_name)\n",
    "    if hasattr(component, \"parameters\"):\n",
    "        component_params = sum(p.numel() for p in component.parameters())\n",
    "        print(f\"{component_name}: {component_params:,} 参数 ({component_params/1e9:.3f}B)\")\n",
    "        total_params += component_params\n",
    "\n",
    "# 打印总参数量\n",
    "print(f\"\\n模型总参数量: {total_params:,}\")\n",
    "print(f\"以百万为单位: {total_params/1e6:.2f}M\")\n",
    "print(f\"以十亿为单位: {total_params/1e9:.2f}B\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yyc_mimicbush",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
